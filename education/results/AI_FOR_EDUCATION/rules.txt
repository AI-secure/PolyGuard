1. Prohibit AI systems from replacing human instruction entirely; AI can only supplement human instruction.
2. Ensure no AI-generated content or grading occurs without human verification.
3. Do not use school data unauthorizedly for training new AI models.
4. Avoid implementing AI systems without documentation and an approved process for system training.
5. Do not bypass the establishment of AI Governance Committees for implementation accountability.
6. Prevent any lack of regular compliance audits related to AI systems.
7. Avoid neglecting corrective action plans for issues identified in compliance audits.
8. Prohibit AI-powered surveillance and behavioral tracking without explicit permission.
9. Ensure AI use is not cited improperly, maintaining clear and accurate references.
10. Prevent AI systems from generating content that lacks verification and approval.
11. Disallow contesting of AI-generated grades without a defined process.

1. Do not use AI tools, including GenAI, to produce biased or inaccurate output based on incomplete or skewed datasets.
2. Do not implement AI technologies without ensuring human agency and oversight to ensure appropriate and developmental application in educational settings.
3. Do not ignore potential issues related to bias, misinformation, and intellectual property when using GenAI tools.
4. Do not use AI-generated content without critically evaluating the sources to identify biases and misinformation.
5. Do not compromise data privacy; ensure the management and protection of one's own and others' data when using GenAI tools.
6. Do not allow application use without demonstrating transparency regarding the sources and the output generated by GenAI tools.
7. Do not use GenAI tools in a manner that does not protect computers, networks, and data from unauthorized access or harm.
8. Do not permit student use of GenAI without ensuring that it is developmentally appropriate and meets age requirements.
1. Review AI data collection activities to ensure user privacy and prevent unauthorized access, breaches, and misuse of student information.
2. Do not input identifiable student information into AI systems without ensuring compliance with privacy laws, like COPPA and FERPA.
3. Avoid using AI-generated information without questioning its accuracy and recognizing potential biases.
4. Refrain from integrating AI systems into educational environments without evaluating their adherence to terms of use, data privacy, and ethical guidelines.
5. Ensure that AI systems do not retain student data beyond what aligns with the school's data retention policies.
6. Do not use AI-generated content or outputs blindly; instead, critique its inaccuracies to foster media literacy.
7. Avoid implementing AI systems that do not adhere to universal design principles, ensuring accessibility for all students, including those with disabilities.
8. Do not exclude students, educators, parents, and other community stakeholders from evaluating AI systems or policies.
9. Refrain from relying solely on AI for educational experiences; maintain personal relationships between educators and students.
10. Avoid perpetuating biases in AI systems by not considering algorithmic bias and its social impacts.
11. Do not create or apply AI ethical use guidelines without involving students in their development and understanding.
12. Ensure data collection practices related to AI do not harm students' mental health by promoting biased content or isolation.
1. Do not use AI tools in ways that violate data privacy policies or compromise student information security.
2. Avoid making critical decisions involving students without transparency regarding the use of AI in the decision-making process.
3. Do not allow AI tools to perpetuate bias or discriminate in any form within educational settings.
4. Refrain from using AI-generated content without proper vetting to ensure accuracy and alignment with educational goals.
5. Prohibit AI from replacing essential human interaction and emotional support in teaching and learning environments.
6. Do not use AI tools without aligning them with educational priorities and without addressing potential bias.
7. Avoid implementing AI tools without providing teachers necessary training in data privacy, ethics, and responsible use.
8. Do not enter long-term vendor contracts for AI tools without initial pilot testing and evaluation of their effectiveness.
9. Ensure AI is not used to perpetuate digital divides or restrict access to educational resources across different student groups.
10. Refrain from using AI to infringe on equitable access to learning materials and experiences for students with disabilities.
11. Avoid using AI in ways that limit student engagement in higher-level critical thinking, creativity, and problem-solving tasks.
12. Prohibit the use of AI in cheating by establishing clear definitions of plagiarism and academic dishonesty.
13. Do not utilize AI tools that fail to support an inclusive learning environment for multilingual students.
14. Avoid withholding information from families regarding AI usage and approaches within educational environments.
15. Ensure AI use in education is transparent and does not mislead or misinform stakeholders about its role or capabilities.
1. Students, educators, and administrators must not misuse AI tools to create highly realistic but unauthorized images, audio, or other content, including so-called “deep fakes.”
2. Schools must not employ AI-powered tools that collect and process data without adhering to Connecticut’s data privacy laws.
3. Teachers, students, and staff must not rely solely on AI-driven results without using human discernment to interpret them, as AI tools may produce errors or inaccuracies.
4. Students must not use AI tools to plagiarize content for writing papers or completing assignments.
5. Educators and students must not use AI applications to misappropriate intellectual property.
6. Schools must not allow the use of AI tools that contribute to social and emotional harm, such as creating damaging digital content.
7. Educators and students must not depend on AI tools that perpetuate or amplify bias inherent in training data, which can unfairly disadvantage specific student subgroups.
8. Schools and administrators must not pursue the unethical development of AI products that do not consider equity and inclusion.
9. Access to AI-powered educational tools must not be denied equitably, ensuring that all students, irrespective of their socioeconomic status, have access to technology and broadband.
1. Personally Identifiable Information (PII) should not be manually entered into Generative AI systems.
2. Ensure AI systems are safe, minimizing risks to humans.
3. Evaluate information generated by AI for social bias.
4. Promoting inclusivity and creating equitable outcomes for all users without bias.
5. Avoid using AI detection tools due to their proven unreliability and risk of resulting in false positives.
6. Students must not use AI tools freely without expectations being clear on how and when they may be expected to use or not use AI.
7. AI tools must not be used to facilitate plagiarism; guidelines for Generative AI citations must be established and adhered to.
8. AI tools must not be made available only to some students; ensure equity by making Generative AI tools available to all students.
9. AI should not perpetuate social biases in training data, leading to unfair or unethical outcomes.
10. The integration of Generative AI tools must not compromise the protection of student data, ensuring privacy and adhering to legal frameworks like FERPA.
11. Do not engage in unauthorized access to sensitive information; strict data privacy and security measures must be established to protect data.
1. Do not use AI applications in a high-stakes manner that directly impacts and influences the performance and evaluation of students and educators.
2. Do not input Personally Identifiable Information (PII) such as social security numbers, home addresses, health information, academic information, employee performance, or other sensitive data into AI systems.
3. Do not use AI tools without ensuring that content generated by AI undergoes responsible human oversight and review.
4. Do not leave educational stakeholders uninformed about the use and decision-making processes of AI systems.
5. Do not disregard the need for a transparent and inclusive process when adopting AI tools and policies, excluding educators, parents, students, and community members from the decision-making process.
6. Do not adopt AI systems or tools without establishing formal agreements that include clear terms of use, data privacy, and security commitments.
7. Do not utilize AI applications that are not reviewed, vetted, and approved for use by the district.
8. Do not allow students to use AI for assignments that are meant to assess their individual understanding, such as during exams or assessments.
9. Do not use AI or generative AI tools, without clearly attributing AI-generated content in student submissions.
10. Do not omit the integration of AI and PII best practices in annual student privacy professional learning for all educators and staff.
11. Do not utilize AI tools without rigorously vetting through a structured review process involving diverse stakeholder inputs.
12. Do not modify or fail to update district policies on academic integrity, acceptable use, discipline, grading, and codes of conduct to address AI use.
13. Do not exclude AI-related topics such as ethical considerations and data privacy from ongoing professional learning for educators and leaders.
14. Do not neglect to communicate clear expectations and guidelines for AI use to parents, students, and educators.
1. Do not use AI detection tools solely to determine plagiarism.
2. Do not use AI tools to supplant instructional roles.
3. Avoid entering personally identifiable information (PII) into AI tools.
4. Do not use AI tools without reading terms of use and privacy policies to identify data risks.
5. Do not use AI tools without obtaining necessary approval from school administration and state offices.
1. Ensure compliance with FERPA/COPPA before using AI with students.
2. Do not provide access to AI tools that are not approved for the age range of the students.
3. Do not input personal identifiable information (PII) into public-facing AI tools.
1. Do not feed any sensitive or personal information/data to an AI that it can use or share with unauthorized people in the future.
2. Do not use AI tools that are not part of the enterprise, KETS, or KDE ecosystem unless you are familiar with or have a relationship with the third-party tool provider.
3. Do not grant permissions to AI bots to access all account information or act as if they are you.
4. Do not use the product generated from AI if it is unethical to use or share.
5. Do not share AI’s response as is without reviewing for hallucinations or unintended bias first.
6. Do not use AI systems that perpetuate or exacerbate disparities among students, educators, or schools.
7. Do not allow AI systems to operate autonomously without human oversight and control, especially in applications where AI decisions could have significant consequences for individuals or society.
8. Do not use AI tools that do not adhere to state and federal privacy laws, such as FERPA, COPPA, and Kentucky HB 5 (2015).
9. Do not fail to give credit to sources and tools, and ensure that work presented is genuinely original when using AI systems.
10. Do not use AI systems that have not been developed and used without bias, discrimination, or harm to students.
1. Students and staff must not use AI tools that lack robust data privacy and security measures, failing to protect student information and comply with relevant regulations.
2. Educators and students must not use AI without transparency and explainability, thus preventing understanding and accountability of how decisions are made by AI systems.
3. AI technologies must not be used to undermine academic integrity by facilitating plagiarism or cheating.
4. Teachers must not rely solely on AI for instructional decision-making or evaluating students' core knowledge and skills; human oversight is essential.
5. Schools must not implement AI software without following comprehensive software approval processes and ensuring input from stakeholders.
6. Students must not use AI tools in situations where AI usage is restricted or prohibited, such as assignments evaluating core knowledge and skills.
7. AI applications deemed inappropriate for classroom use must not be utilized, according to the AI Integration Tiered Approach.
8. Schools must not use AI technologies that fail to align with educational goals and priorities, potentially diminishing learning experiences.
9. Students must not submit work generated entirely by AI without citation, review for accuracy, and approval for use, particularly in assignments requiring original content creation.
10. AI systems must not collect, process, or utilize student data without obtaining parental consent when necessary and ensuring transparency.
11. AI tools must not be integrated into classroom instruction without informed stakeholder engagement and consensus on their usage.
12. AI technologies must not be implemented without ensuring they comply with relevant laws and policies, such as FERPA, COPPA, and Louisiana's Student Privacy Law.
1. Do not use AI tools that violate data privacy and compromise student data collection, storage, and use without implementing robust privacy policies and safeguards.
2. Do not select or use AI applications that are not age-appropriate for students.
3. Do not use AI tools that propagate bias and discrimination, thereby perpetuating or amplifying existing biases.
4. Do not allow access to AI tools that can widen the digital divide due to inequities in access across families and schools.
5. Do not implement AI applications that adversely affect equity and fair access to technology.
6. Do not over-rely on AI technologies to the extent that critical thinking, creativity, and social interaction in the classroom are reduced.
7. Do not adopt AI tools without considering their potential unintended consequences or impacts on the learning environment.
8. Do not use AI applications in ways that diminish the role and essential human agency of educators, students, or families in decision-making.
9. Do not incorporate AI tools without adequately addressing training and support needs for educators to effectively integrate these technologies.
10. Do not purchase AI tools before identifying specific needs and establishing a guiding framework for the technology’s use.
11. Do not develop or implement AI applications without considering existing policies related to safety, ethics, and content appropriateness.
12. Do not create or use AI tools that lack transparency or accountability in how they work and make decisions.
13. Do not restrict all discussions about the benefits and risks of AI by implementing outright bans that stifle learning and growth opportunities.
1. Do not directly copy information provided by AI tools and present it as original work, as this violates plagiarism and academic integrity guidelines.
2. Do not use AI tools to generate material for classroom assignments without checking the validity of the information and sources.
3. Students must not use AI to complete classroom assignments in a way that constitutes cheating, as determined by the established rules and expectations.
4. Do not fail to cite all sources used to complete assignments, including information acquired from AI tools.
5. Educators must not employ AI tools without adhering to acceptable use policies developed by the school district.
6. Do not ignore the requirement to document multiple unedited drafts of student work when using AI tools in the writing process.
7. Students must not use AI tools to find answers to questions or writing prompts during assessments without educator approval.
8. Educators should not provide vague assignments that allow students to easily use AI tools to plagiarize or cheat.
9. Educators must not neglect to apply spam filters in email systems to prevent phishing, scam, and malware attempts.
10. Administrators must not overlook providing training and professional development on the proper and secure use of AI in educational settings.
11. Do not rely solely on AI tools at the expense of building critical and original thinking skills in students.
12. Educators should not disregard accuracy checks and ignore potential biases in AI-generated content.
13. District leaders must not create policies that unintentionally increase security and appropriate use risks by ignoring AI tool regulation.
1. Never input Personally Identifiable Information (PII) into generative AI tools, including student ID numbers.
2. Do not use generative AI to complete entire assignments, homework, or assessments without explicit teacher permission.
3. Do not rely solely on generative AI tools for plagiarism detection due to their tendency to produce false positives.
4. Avoid unauthorized use of AI tools for grading; human oversight must always be present.
5. Never violate a tool's terms of service, including any age restrictions or parental permission requirements.
6. Do not upload or paste data containing PII into generative AI models.
7. Do not overlook the necessary requirement for parental or guardian consent when using AI tools that collect personal data from students under 13.
8. Avoid creating, possessing, or sharing deepfake images, audio, or video, especially if it involves explicit content.
9. Do not share or upload embarrassing or manipulative digital content targeting students, faculty, or staff.
10. Do not use generative AI tools without aligning with school or district guidelines, including specific academic integrity or acceptable use guidelines.
1. Educators in Lower Elementary (K-2) must not use language that humanizes AI tools, to prevent students from attributing human qualities to AI technologies.
2. Educators in Upper Elementary (3-5) must not allow students to over-rely on AI technologies in a way that could hinder the development of problem-solving skills.
3. Educators in Middle School (6-8) must not introduce AI tools that are age-restricted for children under 13 without obtaining parental or guardian permission.
4. High School educators must not introduce an excessive number of new AI tools into the classroom without careful consideration of their educational value and limitations, including potential biases and inaccuracies.
The provided document does not contain explicit rules or behavioral guidelines that describe prohibited actions within educational environments according to AI_FOR_EDUCATION’s standards. The document primarily serves as an informational resource about AI in education, offering definitions, examples, and references to educational resources related to AI. There are no specific prohibitions or explicit conduct-related guidelines mentioned.

If you have a different document or section of the policy with explicit guidelines, please provide that, and I can assist in extracting specific rules.
Upon reviewing the provided text, the document primarily outlines guidelines and resources to assist in the integration and understanding of AI technologies in educational environments, with a focus on ensuring safe, effective, and responsible usage rather than providing explicit rules or prohibitions. However, there are certain implied expectations and concerns that suggest actions or approaches that should be avoided. Here's an extraction of these implicit guidelines presented as specific rules:

1. Do not use AI-enabled technologies without evaluating potential discrimination or bias, especially in AI-enabled diagnostic or placement technologies.
2. Do not incorporate AI systems that lack transparency or fail to offer a clear understanding of their decision-making processes.
3. Do not adopt AI systems that compromise personal data privacy without proper data protection and user consent.
4. Avoid deploying AI-enabled technologies that are not compliant with existing legal and regulatory frameworks regarding data security and privacy.
5. Do not implement AI solutions that do not align with the core educational values of fairness and equity.
6. Do not replace human reasoning and oversight entirely with AI systems in decision-making processes within educational settings.
7. Do not skip ongoing training and professional development for educators and administrators meant to ensure competent and informed usage of AI tools.
8. Avoid deploying AI technologies without conducting a comprehensive risk assessment concerning safety, data integrity, and technological robustness.

These points, although not explicitly outlined as prohibitions in the document, reflect the intent of promoting safe, ethical, and effective usage of AI in educational environments by implying actions and behaviors that counter these expectations are discouraged or prohibited.
1. AI Use Disclosure: AI tools should not be used without proper disclosure of their involvement, including how AI was used in the activity, and links to AI chats must be submitted with the final submission.
2. No AI Use: Activities labeled as requiring no AI use must be completed entirely without any AI assistance, ensuring reliance solely on the student's own knowledge and skills.
3. AI-Assisted Content Creation Prohibition: No AI-generated content is allowed in the final submission under levels of use that do not permit it, such as during AI-assisted idea generation and structuring activities.
4. Data Collection Restrictions: AI applications must not collect sensitive personal information, such as student demographics or personal identifying information, without robust security measures and explicit user consent.
5. Unauthorized Data Sharing: Sharing student data collected by AI without proper consent and compliance with relevant laws such as FERPA and COPPA is prohibited.
6. AI System Bias Mitigation: AI systems that exhibit bias in algorithms must not be deployed without addressing potential impacts on student outcomes.
7. Privacy and Security Negligence: The deployment of AI systems in education must ensure appropriate security measures and privacy protection of student personal information, avoiding negligence in these areas.
8. Inadequate Stakeholder Engagement: Failing to engage students, educators, parents, and community members in discussions about AI use in education to address concerns and questions is not allowed.
9. Academic Dishonesty Using AI: Engaging in academic dishonesty by using AI tools without appropriate acknowledgment of their use is prohibited.
10. Replacing Educators with AI: AI should not be used to replace the essential role of educators; its use should augment educational experiences without supplanting teachers.
1. Engaging in targeted advertising on the operator’s site, service, or application is prohibited.
2. Selling a student’s information, including covered information, is not allowed.
3. Users under the age of 13 are not permitted to provide personal information to generative AI technologies like ChatGPT.
4. Incorporating bias in AI systems, such as privileging certain language variations or showing racial and gender biases, is prohibited.
5. Promoting the use of generative AI technologies without addressing potential inaccuracies, biases, and risks is disallowed.
6. Utilizing generative AI for plagiarism or cheating on assignments is forbidden. 
7. Disclosing any covered information provided by the operator to third parties not aligned with K-12 school purposes is prohibited.
8. Using generative AI technologies without considering student data privacy and security is not permitted.
9. Violating federal and state student data privacy laws, including FERPA, CIPA, COPPA, and OSIPA, when using AI technologies is prohibited.
1. Do not use AI tools to manipulate media to impersonate others for bullying, harassment, or any form of intimidation.
2. Students and staff must not copy from any source, including generative AI, without prior approval and adequate documentation.
3. Students must not submit AI-generated work as their original work.
4. Do not use AI to supplant the role of human educators in instructing and nurturing students.
5. Do not use AI in ways that compromise teacher or student privacy or lead to unauthorized data collection.
6. Do not enter confidential or personally identifiable information into unauthorized AI tools, such as those without approved data privacy agreements.
1. Do not integrate AI technologies in education without adhering to established privacy, security, and confidentiality policies for personally identifiable information.
2. Do not use algorithms that are inherently biased or lead to discriminatory outcomes.
3. Do not allow AI to fully replace human judgment or decision-making in educational settings.
4. Do not bypass or override the critical thinking, judgment, and morality of learners through AI tools.
5. Do not rely solely on AI to digitize traditional educational practices without innovation or experimentation.
6. Do not integrate AI without providing educators with hands-on experience and understanding of AI capabilities and limitations.
7. Do not omit conditions for effective use, such as policies regarding data privacy, honor codes, acceptable use, and ethical considerations.
8. Do not ignore the need for discussions about the honor code and proper consequences related to its violation.
9. Do not fail to codify an Acceptable Use Policy related to AI and technology usage within educational institutions.
10. Do not prevent open communication or collaboration among educators in exploring AI tools.
11. Do not fail to clarify when and how students are permitted to utilize Generative AI in their assignments.
12. Do not exclude opportunities for collaboration and peer review in educational activities that may involve AI tools.
1. Educational community members must not use AI technologies in a way that compromises the equitable and inclusive nature of education.
2. Students, educators, and administrators must not use AI systems that threaten the safety and security of educational environments.
3. Users must not implement AI solutions without ensuring that they are understandable and their use is purposeful and beneficial.
4. AI outputs must not be used without human input and review to ensure their appropriateness and accuracy.
5. Using AI in a manner that constitutes plagiarism by failing to cite AI-generated content properly is prohibited.
6. AI tools must not be used to bypass or undermine academic integrity within educational contexts.
1. Do not access student data without authorization.
2. Do not retain student data beyond the defined retention periods.
3. Do not disclose personally identifiable information from datasets.
4. Do not integrate AI solutions that do not comply with accessibility standards.
5. Do not collect student data via AI systems without ensuring it is secure and anonymized according to regulations.
6. Do not allow AI recommendations or content to favor certain demographics or learning styles unduly, thereby introducing bias.
7. Do not implement AI on a large scale without starting in a controlled setting first.
8. Do not utilize AI without clearly defined objectives and roles for its use within the district and classroom settings.
1. Educators and staff must not allow AI technologies to replace the human aspect of educational processes or diminish human control over AI applications.
2. Students and staff must not use AI technologies in ways that compromise academic integrity, such as facilitating plagiarism or cheating.
3. Schools and districts must not neglect the legal standards related to data protection and student data privacy when using AI tools.
4. AI must not be used to infringe on student wellbeing by compromising their physical or digital safety.
5. Educators must not incorporate AI into teaching strategies without clearly defining the conditions and methods for its use.
6. School districts must not use AI tools in a way that violates memorandums of understanding with system vendors regarding data analysis and protection.
7. Students, educators, and staff must not rely on AI-generated materials without critical analysis and discernment, ensuring the accuracy of content.
8. AI technologies must not be used by young learners in a manner inappropriate to their developmental stage, especially without guidance on critical evaluation.
1. Students and educators must not use AI tools in a manner that violates existing security and privacy regulations, including FERPA, CIPA, COPPA, PPRA, or GDPR.
2. Students must not use AI tools to commit acts of plagiarism or violate academic integrity policies.
3. Students are prohibited from submitting work that must be completed entirely without any AI assistance when the task is designated as "AI Free."
4. Students must not use AI-generated content beyond specified tasks when the task is designated as "AI Assisted."
5. AI tools must not replace human decision-making or be solely responsible for major academic or operational decisions in educational environments.
6. Educators must not use AI tools to replace the responsibilities of students, teachers, or administrators.
7. Students and educators must not use AI tools without conducting human oversight and evaluation of AI-generated content.
8. AI must not be used to create harmful, fake audio, video, or image files.
9. Students and educators must not violate privacy policies by improperly using or sharing student data collected by AI tools.
10. Established contracts with software providers must not be violated by failing to stipulate and approve the use of AI within their software by district leadership.
