Harassment & cyberbullying policies

The safety of our creators, viewers, and partners is our highest priority. We look to each of you to help us protect this unique and vibrant community. It’s important you understand our Community Guidelines, and the role they play in our shared responsibility to keep YouTube safe. Take the time to carefully read the policy below. You can also check out this page for a full list of our guidelines.
We don’t allow content that targets someone with prolonged insults or slurs based on their physical traits or protected group status. We also don’t allow other harmful behaviors, like threats or doxxing. Keep in mind that we take a stricter approach on content that targets minors.

If you find content that violates this policy, report it. Instructions for reporting violations of our Community Guidelines are available here. If you find many videos or comments that you would like to report, you can report the channel. For tips about how to stay safe, keep your account secure, and protect your privacy, check out the Creator Safety Center and Stay safe on YouTube.

If specific threats are made against you and you feel unsafe, report it directly to your local law enforcement agency.

What this policy means for you
If you're posting content
Don’t post content on YouTube if it fits any of the descriptions noted below.

Content that contains prolonged insults or slurs based on someone's intrinsic attributes. These attributes include their protected group status, physical attributes, or their status as a survivor of sexual assault, non-consensual intimate imagery distribution, domestic abuse, child abuse and more.
Content uploaded with the intent to shame, deceive or insult a minor. This means intending to make a minor feel unpleasant emotions, like distress, shame, or worthlessness; intending to trick them to behave in ways that may harm themselves or their property; or engaging in name-calling toward them. A minor is someone under 18 years old.
Other types of content that violate this policy
This policy applies to videos, video descriptions, comments, live streams, and any other YouTube product or feature. Keep in mind that this isn't a complete list. Note that these policies also apply to external links in your content. This can include clickable URLs, verbally directing users to other sites in video and other forms.

Exceptions
If the primary purpose is educational, documentary, scientific, or artistic in nature, we may allow content that includes harassment. These exceptions are not a pass to harass someone. Some examples include:

Debates related to high-profile officials or leaders: Content featuring debates or discussions of topical issues concerning individuals who have positions of power, like high-profile government officials or CEOs of major multinational corporations.
Scripted performances: Insults made in the context of an artistic medium such as scripted satire, stand up comedy, or music (such as a diss track). Note: This exception is not a pass to harass someone and claim “I was joking.”
Harassment education or awareness: Content that features actual or simulated harassment for documentary purposes or with willing participants (such as actors) to combat cyberbullying or raise awareness.
Note: We take a harder line on content that maliciously insults someone based on their protected group status, regardless of whether or not they are a high-profile individual.

Monetization and other penalties
In some rare cases, we may remove content or issue other penalties when a creator:

Repeatedly encourages abusive audience behavior.
Repeatedly targets, insults and abuses an identifiable individual based on their intrinsic attributes across several uploads.
Exposes an individual to risks of physical harm based on the local social or political context.
Creates content that harms the YouTube community by persistently inciting hostility between creators for personal financial gain.
Examples
Here are some examples of content that’s not allowed on YouTube:

Repeatedly showing pictures of someone and then making statements like “Look at this creature’s teeth, they’re so disgusting!”, with similar commentary targeting intrinsic attributes throughout the video.
Targeting an individual based on their membership in a protected group, such as by saying: “Look at this [slur targeting a protected group]!”
Using an extreme insult to dehumanize an individual based on their intrinsic attributes. For example: “Look at this dog of a woman! She’s not even a human being — she must be some sort of mutant or animal!”
Targeting an individual and expressing a wish for their death or serious injury: “I hate her so much. I wish she’d just get hit by a truck and die.”
Depicting an identifiable individual being murdered or seriously injured. For example: A video includes a clip from a movie, where one character is brutally shot and killed. The video is edited so that a real individual’s photo is placed over the actor’s face.
Threatening someone’s physical safety. This includes explicit threats like, “When I see you on Saturday, I’m going to kill you.” This also includes implying violence by making statements like, “You better watch out, I’m coming for you” while brandishing a weapon.
Posting an individual’s non-public personally identifiable information, like a phone number, home address, or email address, to direct abusive attention or traffic toward them. For example, saying, “I got a hold of their phone number. Call and leave messages until they pick up!”
“Raiding” or directing malicious abuse to identifiable individuals through in-game voice chat or messages during a stream.
Directing users to leave abusive comments in another creator's comment section.
Linking to off platform sites that host or feature non-consensual intimate imagery.
Requesting that other users get in touch to share non-consensual intimate imagery.
“Swatting” or other prank calls to emergency or crisis response services, or encouraging viewers to act in this or any other harassing behavior.
Stalking or attempting to blackmail users.
Video game content which has been developed or modified (“modded”) to promote violence against an individual.
Remember, this list isn't exhaustive. Don't post content if you think it might violate this policy.

What happens if content violates this policy
If your content violates this policy, we will remove the content and send you an email to let you know. If we can’t verify that a link you post is safe, we may remove the link. Note that violative URLs posted within the video itself or in the video’s metadata may result in the video being removed.

If this is your first time violating our Community Guidelines, you'll likely get a warning with no penalty to your channel. You will have the option to take a policy training to allow the warning to expire after 90 days. The 90 day period starts from when the training is completed, not when the warning is issued. However, if the same policy is violated within that 90 day window, the warning may not expire and your channel may be given a strike. If you violate a different policy after completing the training, you will get another warning.

If you get 3 strikes within 90 days, your channel may be terminated. Learn more about our strikes system.

We may terminate your channel or account for repeated violations of the Community Guidelines or Terms of Service. We may also terminate your channel or account after a single case of severe abuse, or when the channel is dedicated to a policy violation. We may prevent repeat offenders from taking policy trainings in the future. Learn more about channel or account terminations.